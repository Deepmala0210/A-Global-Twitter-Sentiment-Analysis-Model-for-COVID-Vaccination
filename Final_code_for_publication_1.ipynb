{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPWGgt6LxDiQ"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install --quiet gspread pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VcsPFnr_0zhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gspread\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "from google.colab import files\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer, AutoConfig\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "from scipy.special import softmax\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "ORkS53O40-3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IMPORTANT NOTE\n",
        "\n",
        "The following notebook accesses a private Google Sheet containing\n",
        "hydrated Twitter data.\n",
        "\n",
        "Due to Twitter/X Terms of Service and privacy constraints,\n",
        "raw tweet text and user location data are **not included**\n",
        "in this public repository. Credentials and spreadsheet keys\n",
        "are therefore intentionally omitted.\n",
        "\n",
        "To reproduce the experiment:\n",
        "\n",
        "1. Hydrate the published Tweet IDs using the Twitter API to retrieve  \n",
        "   **Tweet Text** and **Location** fields.\n",
        "2. Store the hydrated data in a Google Sheet.  \n",
        "3. Provide your own Google Service Account credentials.\n",
        "\n",
        "**All subsequent analyses assume that these steps have been completed**\n"
      ],
      "metadata": {
        "id": "mQy6rha-SU-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the path to your credentials file in Drive\n",
        "gc = gspread.service_account(filename=\"PATH_TO_YOUR_CREDENTIALS.json\")"
      ],
      "metadata": {
        "id": "8EHOPk5WSepg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open your Google Sheet by key\n",
        "sh = gc.open_by_key(\"YOUR_SPREADSHEET_KEY\")\n",
        "worksheet = sh.get_worksheet(0)"
      ],
      "metadata": {
        "id": "Fv5Mryo1SiAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get records\n",
        "res = worksheet.get_all_records()"
      ],
      "metadata": {
        "id": "HwwExxSqSpVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to DataFrame\n",
        "df = pd.DataFrame(res)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "wjj99TPISsXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets = df['Tweet Text'].tolist()"
      ],
      "metadata": {
        "id": "zrE7icUIqwX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets"
      ],
      "metadata": {
        "id": "7_m7ZLRkq9qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(tweets))"
      ],
      "metadata": {
        "id": "w6TMeZcbrShN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tweet_ID = df['Tweet ID'].tolist()"
      ],
      "metadata": {
        "id": "iXfoPI2_CLe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Location = df['Location'].tolist()"
      ],
      "metadata": {
        "id": "8aXjdN4KDJmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "id": "VmW_YLWmNwN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    new_text = []\n",
        "    for t in text.split(\" \"):\n",
        "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
        "        t = 'http' if t.startswith('http') else t\n",
        "        new_text.append(t)\n",
        "    return \" \".join(new_text)"
      ],
      "metadata": {
        "id": "tHXs5N_Zrey9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "config = AutoConfig.from_pretrained(MODEL)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
      ],
      "metadata": {
        "id": "SpdZuVoVrfFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "2V6ABFBzN3a2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Check label mapping ---\n",
        "print(config.id2label)"
      ],
      "metadata": {
        "id": "LjRzuRjluoEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_predictions = []\n",
        "tweet_logits = []  # to store raw logits\n",
        "tweet_probs = []   # to store probabilities\n",
        "tweet_s = []  # to store p_pos - p_neg\n",
        "tweet_sadj = []  # to store (1-p_neu)*(p_pos - p_neg)"
      ],
      "metadata": {
        "id": "G6dyqX6zUcRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(tweets)):\n",
        "    #batch_tweets = tweets[i:i+BATCH_SIZE]\n",
        "    #batch_texts = [preprocess(text) for text in batch_tweets]\n",
        "    text = tweets[i]\n",
        "    text = preprocess(text)\n",
        "    encoded_input = tokenizer(text, padding=True, truncation=True, max_length = 256, return_tensors='pt').to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(**encoded_input)\n",
        "\n",
        "    # Raw logits BEFORE softmax\n",
        "    logits = output.logits[0].cpu().numpy()\n",
        "\n",
        "    # --- Convert to probabilities ---\n",
        "    probs = softmax(logits)  # converts logits â†’ probabilities\n",
        "    p_neg, p_neu, p_pos = probs\n",
        "\n",
        "    s = p_pos - p_neg\n",
        "    s_adj = (1.0 - p_neu) * s\n",
        "\n",
        "    # --- Class label based on maximum probability ---\n",
        "    pred_label = config.id2label[np.argmax(probs)]\n",
        "\n",
        "    # --- Save results ---\n",
        "    sentiment_predictions.append(pred_label)\n",
        "    tweet_logits.append(logits)\n",
        "    tweet_probs.append(probs)\n",
        "    tweet_s.append(s)\n",
        "    tweet_sadj.append(s_adj)\n",
        "\n",
        "    print(f\"{i}: Label={pred_label}, Score={s_adj:.3f}, Probabilities={probs}\")\n",
        "\n",
        "    #scores = output[0][0].detach().numpy()\n",
        "    #scores = softmax(scores)\n",
        "    #ranking = np.argsort(scores)\n",
        "    #ranking = ranking[::-1]\n",
        "    #predictions = config.id2label[ranking[0]]\n",
        "    #print(i,predictions)\n",
        "    #sentiment_predictions.extend([predictions])"
      ],
      "metadata": {
        "id": "zAr6A5aFrfQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, lst in zip(\n",
        "    [\"sentiment_predictions\", \"tweet_logits\", \"tweet_probs\", \"tweet_s\", \"tweet_sadj\"],\n",
        "    [sentiment_predictions, tweet_logits, tweet_probs, tweet_s, tweet_sadj]\n",
        "):\n",
        "    print(name, len(lst))"
      ],
      "metadata": {
        "id": "gZgiVHmTEYu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame({\n",
        "    'tweet_text': tweets,\n",
        "    'pred_label': sentiment_predictions,\n",
        "    'raw_logit': tweet_logits,\n",
        "    'probabilities': tweet_probs,\n",
        "    'tweet_logit': tweet_s,\n",
        "    'final_tweet_logit': tweet_sadj,\n",
        "    'Tweet_ID': Tweet_ID,\n",
        "    'Location': Location\n",
        "})"
      ],
      "metadata": {
        "id": "BixehtVVF4R9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "tz8Lco4dV7In"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = data[['tweet_text','pred_label','final_tweet_logit','Location','Tweet_ID']]"
      ],
      "metadata": {
        "id": "egyE-y3BU6pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive = df1[df1['pred_label']=='positive']\n",
        "neutral = df1[df1['pred_label']=='neutral']\n",
        "negative = df1[df1['pred_label']=='negative']"
      ],
      "metadata": {
        "id": "un-O2r5KPI5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"positive:\",len(positive))\n",
        "print(\"neutral:\",len(neutral))\n",
        "print(\"negative :\",len(negative))"
      ],
      "metadata": {
        "id": "mQg2law8PQ5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['Tweet_ID'] = df1['Tweet_ID'].astype(str)"
      ],
      "metadata": {
        "id": "Xcgsq85SLBOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the DataFrame (df1) into a Google Sheet\n",
        "sheets = sh.get_worksheet(2)\n",
        "sheets.update([df1.columns.values.tolist()] + df1.values.tolist())"
      ],
      "metadata": {
        "id": "xZYnSgL2VMzV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}