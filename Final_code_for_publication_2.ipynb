{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "pip install psutil"
      ],
      "metadata": {
        "id": "zEiFJiEI4TF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPWGgt6LxDiQ"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install --quiet gspread pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VcsPFnr_0zhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gspread\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "from google.colab import files\n",
        "import tracemalloc\n",
        "import time\n",
        "import psutil, os\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer, AutoConfig\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "from scipy.special import softmax"
      ],
      "metadata": {
        "id": "ORkS53O40-3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "vBbnaRI6zCig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fd = pd.read_excel(\"finaldata.xlsx\")\n",
        "fd"
      ],
      "metadata": {
        "id": "GsSp_xv6zSTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Bangladesh_list = fd[fd['Country'] == 'Bangladesh']\n",
        "Bangladesh_list = Bangladesh_list.Location.unique().tolist()\n",
        "print(len(Bangladesh_list))\n",
        "print(Bangladesh_list)"
      ],
      "metadata": {
        "id": "-zaX7ZjLzwI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "India_list = fd[fd['Country'] == 'India']\n",
        "India_list = India_list.Location.unique().tolist()\n",
        "print(len(India_list))\n",
        "print(India_list)"
      ],
      "metadata": {
        "id": "dxTUOsHd1lJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Canada_list = fd[fd['Country'] == 'Canada']\n",
        "Canada_list = Canada_list.Location.unique().tolist()\n",
        "print(len(Canada_list))\n",
        "print(Canada_list)"
      ],
      "metadata": {
        "id": "bKdzRxfh11Tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Us_list = fd[fd['Country'] == 'United States']\n",
        "Us_list = Us_list.Location.unique().tolist()\n",
        "print(len(Us_list))\n",
        "print(Us_list)"
      ],
      "metadata": {
        "id": "HMZVVigs1_61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Uk_list = fd[fd['Country'] == 'United Kingdom']\n",
        "Uk_list = Uk_list.Location.unique().tolist()\n",
        "print(len(Uk_list))\n",
        "print(Uk_list)"
      ],
      "metadata": {
        "id": "8g_PZzbZ2W3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "France_list = fd[fd['Country'] == 'France']\n",
        "France_list = France_list.Location.unique().tolist()\n",
        "print(len(France_list))\n",
        "print(France_list)"
      ],
      "metadata": {
        "id": "IrFo-Gx72g5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Australia_list = fd[fd['Country'] == 'Australia']\n",
        "Australia_list = Australia_list.Location.unique().tolist()\n",
        "print(len(Australia_list))\n",
        "print(Australia_list)"
      ],
      "metadata": {
        "id": "qOewlDN72o50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Pakistan_list = fd[fd['Country'] == 'Pakistan']\n",
        "Pakistan_list = Pakistan_list.Location.unique().tolist()\n",
        "print(len(Pakistan_list))\n",
        "print(Pakistan_list)"
      ],
      "metadata": {
        "id": "eta1yz4D20o9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Netherlands_list = fd[fd['Country'] == 'Netherlands']\n",
        "Netherlands_list = Netherlands_list.Location.unique().tolist()\n",
        "print(len(Netherlands_list))\n",
        "print(Netherlands_list)"
      ],
      "metadata": {
        "id": "7xy9jSar28XT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Germany_list = fd[fd['Country'] == 'Germany']\n",
        "Germany_list = Germany_list.Location.unique().tolist()\n",
        "print(len(Germany_list))\n",
        "print(Germany_list)"
      ],
      "metadata": {
        "id": "h742EEpP3VTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "roCJCvR4oSlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coviddata = pd.read_excel(\"Country_dataset.xlsx\")\n",
        "coviddata"
      ],
      "metadata": {
        "id": "k66swbUBp4YY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coviddata['increase_confirmed'] = coviddata['Confirmed 22nd June']-coviddata['Confirmed 1st april']\n",
        "coviddata['increase_confirmed'] = coviddata['increase_confirmed']/coviddata['Population']\n",
        "coviddata['increase_confirmed']"
      ],
      "metadata": {
        "id": "jtZWdZMVqAno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coviddata['increase_deaths'] = coviddata['Deaths 22nd June']-coviddata['Deaths 1st april']\n",
        "coviddata['increase_deaths'] = coviddata['increase_deaths']/coviddata['Population']\n",
        "coviddata['increase_deaths']"
      ],
      "metadata": {
        "id": "VlrvUVRwqENU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max3 = coviddata['increase_confirmed'].max()\n",
        "min3 = coviddata['increase_confirmed'].min()\n",
        "max4 = coviddata['increase_deaths'].max()\n",
        "min4 = coviddata['increase_deaths'].min()"
      ],
      "metadata": {
        "id": "QM-SeJ9iqMWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(max3,min3,max4,min4)"
      ],
      "metadata": {
        "id": "935noiCjqQM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coviddata['normalized_increase_confirmed'] = coviddata['increase_confirmed'].apply(lambda x: (((x-min3)+0.0001)/((max3-min3)+0.0001)))"
      ],
      "metadata": {
        "id": "jKRdWSB6qSFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coviddata['normalized_increase_deaths'] = coviddata['increase_deaths'].apply(lambda y: (((y-min4)+0.0001)/((max4-min4)+0.0001)))"
      ],
      "metadata": {
        "id": "8JsMBvjIqoY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coviddata['intensity'] = (coviddata['normalized_increase_confirmed']+coviddata['normalized_increase_deaths'])/2\n",
        "# 'intensity' corresponds to the Severity Value (SV) as described in the manuscript.\n",
        "coviddata[['Country','intensity']]"
      ],
      "metadata": {
        "id": "-IU6p3Cpqsi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Important NOTE\n",
        "\n",
        "The cells below require a `Location` column derived from hydrated Twitter data.\n",
        "\n",
        "Due to Twitter/X Developer Policy and privacy constraints, raw tweet text and\n",
        "user location are not included in the public release.\n",
        "\n",
        "To reproduce the results:\n",
        "1. Hydrate the published Tweet IDs using the Twitter API to retrieve the  \n",
        "   **tweet_text** and **Location** fields.\n",
        "2. Run *Final_code_for_publication_1.ipynb* to compute local sentiment labels\n",
        "   and sentiment scores.\n",
        "3. Store the resulting dataset in a Google Sheet using your own Google\n",
        "   Service Account credentials.\n",
        "\n",
        "**All subsequent analyses assume these steps have been completed.**\n",
        "\n",
        "In our private execution, we store the following fields in a Google Sheet:\n",
        "- `tweet_text`\n",
        "- `Tweet_ID`\n",
        "- `Location`\n",
        "- `pred_label` (local sentiment)\n",
        "- `final_tweet_logit` (Sentiment Score)\n",
        "\n",
        "However, **credentials and spreadsheet keys are NOT included** in this public\n",
        "repository for ethical reasons and to comply with Twitter/X Terms of Service.\n"
      ],
      "metadata": {
        "id": "yGp4uvxgJgSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the path to your credentials file in Drive\n",
        "gc = gspread.service_account(filename=\"PATH_TO_YOUR_CREDENTIALS.json\")"
      ],
      "metadata": {
        "id": "U7JrkxSM1IDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open your Google Sheet by key\n",
        "sh = gc.open_by_key(\"YOUR_SPREADSHEET_KEY\")"
      ],
      "metadata": {
        "id": "CuuubKNz1PDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "worksheet1 = sh.get_worksheet(2)"
      ],
      "metadata": {
        "id": "D4C6KYGbDHnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get records\n",
        "res1 = worksheet1.get_all_records()"
      ],
      "metadata": {
        "id": "owS0VvduDHnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1=pd.DataFrame(res1)\n",
        "data1"
      ],
      "metadata": {
        "id": "4gvyyIxsDO80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive = data1[data1['pred_label']=='positive']\n",
        "neutral = data1[data1['pred_label']=='neutral']\n",
        "negative = data1[data1['pred_label']=='negative']"
      ],
      "metadata": {
        "id": "c8iIWUE9kvqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"positive:\",len(positive))\n",
        "print(\"neutral:\",len(neutral))\n",
        "print(\"negative :\",len(negative))"
      ],
      "metadata": {
        "id": "CB6QJrFKlDZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1['Location']=data1['Location'].str.lower()\n",
        "#list1= data1.Location.unique().tolist()\n",
        "#print(list1)"
      ],
      "metadata": {
        "id": "cy4WXItclmVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1['Country']=''\n",
        "data1.loc[data1['Location'].isin(India_list),'Country']='india'\n",
        "data1.loc[data1['Location'].isin(Canada_list),'Country']='canada'\n",
        "data1.loc[data1['Location'].isin(Us_list),'Country']='us'\n",
        "data1.loc[data1['Location'].isin(Uk_list),'Country']='united kingdom'\n",
        "data1.loc[data1['Location'].isin(France_list),'Country']='france'\n",
        "data1.loc[data1['Location'].isin(Bangladesh_list),'Country']='bangladesh'\n",
        "data1.loc[data1['Location'].isin(Australia_list),'Country']='australia'\n",
        "data1.loc[data1['Location'].isin(Pakistan_list),'Country']='pakistan'\n",
        "data1.loc[data1['Location'].isin(Netherlands_list),'Country']='netherlands'\n",
        "data1.loc[data1['Location'].isin(Germany_list),'Country']='germany'\n",
        "data1[['Location','Country']]"
      ],
      "metadata": {
        "id": "dfyhXEQdndyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finaldata = data1"
      ],
      "metadata": {
        "id": "Hvhc8nAmxa6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finaldata"
      ],
      "metadata": {
        "id": "UjoaR_qNx_P_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finaldata.replace('', np.nan, inplace=True)\n",
        "finaldata = finaldata.dropna(subset=['Country'])"
      ],
      "metadata": {
        "id": "XmBG2BCPyFw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finaldata"
      ],
      "metadata": {
        "id": "CHL6eOdA1-YS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finaldata['SV']=''\n",
        "finaldata.loc[finaldata['Country']=='canada','SV']=0.513569\n",
        "finaldata.loc[finaldata['Country']=='india','SV']=0.683371\n",
        "finaldata.loc[finaldata['Country']=='us','SV']=0.578305\n",
        "finaldata.loc[finaldata['Country']=='united kingdom','SV']=0.278029\n",
        "finaldata.loc[finaldata['Country']=='bangladesh','SV']=0.228202\n",
        "finaldata.loc[finaldata['Country']=='france','SV']=0.855757\n",
        "finaldata.loc[finaldata['Country']=='australia','SV']=0.154538\n",
        "finaldata.loc[finaldata['Country']=='pakistan','SV']=0.231838\n",
        "finaldata.loc[finaldata['Country']=='netherlands','SV']=0.756880\n",
        "finaldata.loc[finaldata['Country']=='germany','SV']=0.637414"
      ],
      "metadata": {
        "id": "Fsz_uuTH2zV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finaldata"
      ],
      "metadata": {
        "id": "Tr7K_u-d3hJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ordered_cats = [\"negative\", \"neutral\", \"positive\"]\n",
        "finaldata[\"sentiment_ord\"] = pd.Categorical(finaldata[\"pred_label\"],\n",
        "                                    categories=ordered_cats,\n",
        "                                    ordered=True)"
      ],
      "metadata": {
        "id": "XsdcZQea_oII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check counts by class\n",
        "print(finaldata[\"sentiment_ord\"].value_counts(dropna=False))"
      ],
      "metadata": {
        "id": "Lc5Kwwgd_7T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive = finaldata[finaldata['pred_label']=='positive']\n",
        "neutral = finaldata[finaldata['pred_label']=='neutral']\n",
        "negative = finaldata[finaldata['pred_label']=='negative']"
      ],
      "metadata": {
        "id": "rVPW3LgdTJgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"positive:\",len(positive))\n",
        "print(\"neutral:\",len(neutral))\n",
        "print(\"negative :\",len(negative))"
      ],
      "metadata": {
        "id": "OeMer9J4TQJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finaldata"
      ],
      "metadata": {
        "id": "DPdrFGudAim5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert SV to numeric\n",
        "finaldata[\"SV\"] = pd.to_numeric(finaldata[\"SV\"], errors=\"coerce\")"
      ],
      "metadata": {
        "id": "ikCooUrRcUcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(finaldata[\"SV\"].dtype)\n",
        "print(finaldata[\"SV\"].unique()[:10])"
      ],
      "metadata": {
        "id": "3n-uvycrcaVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bambi pymc arviz"
      ],
      "metadata": {
        "id": "2QU1ctOVCjfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import bambi as bmb\n",
        "import pymc as pm\n",
        "import arviz as az\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from scipy.stats import spearmanr\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "l4gydm3lCmhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(123)\n",
        "random.seed(123)"
      ],
      "metadata": {
        "id": "TrCOaLsrZl8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OPTION 1: Run this cell if you want an overall train–test split across all countries\n",
        "train_data, test_data = train_test_split(\n",
        "    finaldata,\n",
        "    test_size=0.30,\n",
        "    stratify=finaldata[\"sentiment_ord\"],\n",
        "    random_state=123\n",
        ")\n"
      ],
      "metadata": {
        "id": "_UMHH7iKlJcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OPTION 2: Run this cell if you want a country-level train–test split\n",
        "holdout_countries = [\"india\", \"netherlands\"]   # example\n",
        "train_data = finaldata[~finaldata[\"Country\"].isin(holdout_countries)].copy()\n",
        "test_data  = finaldata[ finaldata[\"Country\"].isin(holdout_countries)].copy()"
      ],
      "metadata": {
        "id": "x26yIAs-yOcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data), len(test_data))"
      ],
      "metadata": {
        "id": "N5QUacAyy2rA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process = psutil.Process(os.getpid())"
      ],
      "metadata": {
        "id": "5PrVpbd77kYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = bmb.Model(\n",
        "    \"sentiment_ord ~ final_tweet_logit * SV + (1 | Country)\",\n",
        "    train_data,\n",
        "    family=\"cumulative\"\n",
        ")"
      ],
      "metadata": {
        "id": "-NIrw-xW7sDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tracemalloc.start()\n",
        "start_train = time.time()\n",
        "\n",
        "idata = model.fit(\n",
        "    draws=1000,\n",
        "    tune=1500,\n",
        "    chains=2,\n",
        "    cores=1,\n",
        "    target_accept=0.97,\n",
        "    random_seed=123\n",
        ")\n",
        "\n",
        "train_time = time.time() - start_train\n",
        "\n",
        "current, peak = tracemalloc.get_traced_memory()\n",
        "tracemalloc.stop()\n",
        "\n",
        "print(f\"Training time: {train_time:.2f} seconds\")\n",
        "print(f\"Peak memory during training: {peak / (1024 * 1024):.2f} MB\")\n"
      ],
      "metadata": {
        "id": "sgqxoUWVoXyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tracemalloc.start()\n",
        "start_test = time.time()\n",
        "\n",
        "# Set sample_new_groups=True for OPTION 2 (country-level train–test split);\n",
        "# keep it False for OPTION 1 (overall train–test split).\n",
        "\n",
        "model.predict(idata, data=test_data, kind=\"response\", sample_new_groups=True)\n",
        "\n",
        "inference_time = time.time() - start_test\n",
        "current, peak = tracemalloc.get_traced_memory()\n",
        "tracemalloc.stop()\n",
        "\n",
        "print(f\"Inference time: {inference_time:.4f} seconds\")\n",
        "print(f\"Peak memory during prediction: {peak / (1024 * 1024):.2f} MB\")\n"
      ],
      "metadata": {
        "id": "DLwCzp8eqX_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(idata.posterior_predictive)"
      ],
      "metadata": {
        "id": "1oS6dx6UtC4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract samples: shape (chains, draws, n_obs)\n",
        "pp_samples = idata.posterior_predictive[\"sentiment_ord\"].values\n",
        "C, D, N = pp_samples.shape\n",
        "K = 3  # classes 0..2"
      ],
      "metadata": {
        "id": "nngmNhssxGwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idata.posterior_predictive[\"sentiment_ord\"].shape"
      ],
      "metadata": {
        "id": "Swxo9wJjm9G4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape to (S, N) where S = C*D (all posterior predictive draws)\n",
        "samples = pp_samples.reshape(-1, N)   # shape (S, N)"
      ],
      "metadata": {
        "id": "ZeYqnn9mxIX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute class probabilities by frequency across draws\n",
        "probs = np.zeros((N, K))\n",
        "for k in range(K):\n",
        "    probs[:, k] = (samples == k).mean(axis=0)  # P(y=k) per observation"
      ],
      "metadata": {
        "id": "Cspixe04xM9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_argmax = probs.argmax(axis=1)"
      ],
      "metadata": {
        "id": "Qq_Ndozd-YOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Expected ordinal value\n",
        "expected_vals = (probs * np.arange(K)).sum(axis=1)  # shape (N,)"
      ],
      "metadata": {
        "id": "5Sw4FiDLxR1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# True labels\n",
        "y_true = test_data[\"sentiment_ord\"].cat.codes.values  # 0/1/2"
      ],
      "metadata": {
        "id": "cSjveKWdxVEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics\n",
        "# MAE, MSE, Spearman\n",
        "mae_expected = mean_absolute_error(y_true, expected_vals)\n",
        "mse_expected = mean_squared_error(y_true, expected_vals)\n",
        "spearman_expected, spearman_p = spearmanr(y_true, expected_vals)"
      ],
      "metadata": {
        "id": "3flXTaj0xbC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Expected-value ===\")\n",
        "print(\"MAE:\", mae_expected)\n",
        "print(\"MSE:\", mse_expected)\n",
        "print(\"Spearman:\", spearman_expected, spearman_p)"
      ],
      "metadata": {
        "id": "BBExt9BpxfOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(\"MAE_argmax:\", mean_absolute_error(y_true, pred_argmax))\n",
        "print(\"Accuracy:\",accuracy_score(y_true, pred_argmax))"
      ],
      "metadata": {
        "id": "pTQuoAk--iix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brier = np.mean(np.sum((probs - np.eye(K)[y_true])**2, axis=1))\n",
        "print(\"Brier score:\", brier)"
      ],
      "metadata": {
        "id": "-50GZDRsYRTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_ece(y_true, probs, n_bins=10):\n",
        "    confidences = probs.max(axis=1)\n",
        "    preds = probs.argmax(axis=1)\n",
        "    ece = 0.0\n",
        "    bins = np.linspace(0.0, 1.0, n_bins+1)\n",
        "    for i in range(n_bins):\n",
        "        mask = (confidences > bins[i]) & (confidences <= bins[i+1])\n",
        "        if mask.sum() == 0:\n",
        "            continue\n",
        "        acc = (preds[mask] == y_true[mask]).mean()\n",
        "        conf = confidences[mask].mean()\n",
        "        ece += (mask.sum() / len(y_true)) * abs(acc - conf)\n",
        "    return ece\n",
        "\n",
        "ece = compute_ece(y_true, probs, n_bins=10)\n",
        "print(\"ECE:\", ece)"
      ],
      "metadata": {
        "id": "jx9blQtZYRg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bootstrap_ci_mae(y_true, expected_vals, B=1000):\n",
        "    n = len(y_true)\n",
        "    stats = []\n",
        "    for _ in range(B):\n",
        "        idx = np.random.choice(n, n, replace=True)\n",
        "        stats.append(mean_absolute_error(y_true[idx], expected_vals[idx]))\n",
        "    return np.percentile(stats, [2.5, 97.5])\n",
        "\n",
        "print(\"MAE_expected 95% CI:\", bootstrap_ci_mae(y_true, expected_vals, B=1000))"
      ],
      "metadata": {
        "id": "xapSh12iYRxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_full = bmb.Model(\n",
        "    \"sentiment_ord ~ final_tweet_logit * SV + (1 | Country)\",\n",
        "    finaldata,\n",
        "    family=\"cumulative\"\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "4szY1ESJdOiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tracemalloc.start()\n",
        "start_trainf = time.time()\n",
        "\n",
        "idata_full = model_full.fit(\n",
        "    draws=1000,\n",
        "    tune=1500,\n",
        "    chains=2,\n",
        "    cores=1,\n",
        "    target_accept=0.97,\n",
        "    random_seed=123\n",
        ")\n",
        "\n",
        "train_timef = time.time() - start_trainf\n",
        "current, peak = tracemalloc.get_traced_memory()\n",
        "tracemalloc.stop()\n",
        "\n",
        "print(f\"Full dataset Training time: {train_timef:.2f} seconds\")\n",
        "print(f\"Peak memory during full dataset training: {peak / (1024 * 1024):.2f} MB\")\n",
        "\n"
      ],
      "metadata": {
        "id": "dUdTVwwXFKDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_full.predict(\n",
        "    idata_full,\n",
        "    data=finaldata,\n",
        "    kind=\"response\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "jSjjdZLIjhWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idata_full.posterior_predictive[\"sentiment_ord\"].shape"
      ],
      "metadata": {
        "id": "MXOiwMXekrnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pp_samples_full = idata_full.posterior_predictive[\"sentiment_ord\"].values\n",
        "C, D, N = pp_samples_full.shape   # N = size of full dataset\n",
        "K = 3\n",
        "\n",
        "# reshape\n",
        "samples_full = pp_samples_full.reshape(-1, N)\n",
        "\n",
        "# compute probabilities\n",
        "probs_full = np.zeros((N, K))\n",
        "for k in range(K):\n",
        "    probs_full[:, k] = (samples_full == k).mean(axis=0)\n",
        "\n",
        "# expected ordinal intensity\n",
        "#expected_vals_full = (probs_full * np.arange(K)).sum(axis=1)\n"
      ],
      "metadata": {
        "id": "U1OqCpfFk-5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = finaldata.copy()\n",
        "df['p_neg'] = probs_full[:, 0]\n",
        "df['p_neu'] = probs_full[:, 1]\n",
        "df['p_pos'] = probs_full[:, 2]\n",
        "df['max_p'] = probs_full.max(axis=1)\n",
        "df['pred'] = probs_full.argmax(axis=1)  # hard model label 0/1/2\n",
        "df['ordinal_label'] = pd.Categorical.from_codes(df['pred'], categories=['negative','neutral','positive'])"
      ],
      "metadata": {
        "id": "BXA8R_jrBjxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_intensity_labels(df):\n",
        "    out = df.copy()\n",
        "\n",
        "    class_names = ['NEGATIVE', 'NEUTRAL', 'POSITIVE']\n",
        "    prob_cols   = ['p_neg', 'p_neu', 'p_pos']\n",
        "\n",
        "    # Two new columns: one for median thresholding and one for mean thresholding\n",
        "    out['intensity_label_median'] = None\n",
        "    out['intensity_label_mean']   = None\n",
        "\n",
        "    for k, (cls, colname) in enumerate(zip(class_names, prob_cols)):\n",
        "\n",
        "        mask_class = (out['pred'] == k)\n",
        "\n",
        "        # -------- Median threshold --------\n",
        "        thr_median = out.loc[mask_class, colname].median()\n",
        "        print(thr_median)\n",
        "\n",
        "        out.loc[mask_class & (out[colname] >= thr_median),\n",
        "                'intensity_label_median'] = f\"{cls} WITH HIGH INTENSITY\"\n",
        "        out.loc[mask_class & (out[colname] < thr_median),\n",
        "                'intensity_label_median'] = f\"{cls} WITH LOW INTENSITY\"\n",
        "\n",
        "        # -------- Mean threshold --------\n",
        "        thr_mean = out.loc[mask_class, colname].mean()\n",
        "        print(thr_mean)\n",
        "\n",
        "        out.loc[mask_class & (out[colname] >= thr_mean),\n",
        "                'intensity_label_mean'] = f\"{cls} WITH HIGH INTENSITY\"\n",
        "        out.loc[mask_class & (out[colname] < thr_mean),\n",
        "                'intensity_label_mean'] = f\"{cls} WITH LOW INTENSITY\"\n",
        "\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "hOgQRVkHUSWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the function\n",
        "df_median = make_intensity_labels(df)"
      ],
      "metadata": {
        "id": "FyXWQaFKjj0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_median['intensity_label_mean'].value_counts()"
      ],
      "metadata": {
        "id": "COH7MmWgk05c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_median['intensity_label_median'].value_counts()"
      ],
      "metadata": {
        "id": "QYR5hu3Ph1Uk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_median"
      ],
      "metadata": {
        "id": "Pdey2tUIk1JD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_median['Tweet_ID'] = df_median['Tweet_ID'].astype(str)"
      ],
      "metadata": {
        "id": "Kexw2ZHFkRop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_median.to_excel(\"ordinalfinal.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "uMcG96DangG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"ordinalfinal.xlsx\")"
      ],
      "metadata": {
        "id": "MSWfR5sUn2Qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = az.summary(idata_full, var_names=[\"SV\", \"final_tweet_logit\", \"final_tweet_logit:SV\"], round_to=2)\n",
        "print(summary)"
      ],
      "metadata": {
        "id": "y_ojgOGEOsNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thresholds_summary = az.summary(\n",
        "    idata_full,\n",
        "    var_names=[\"threshold\"],\n",
        "    round_to=2,\n",
        ")\n",
        "print(thresholds_summary)"
      ],
      "metadata": {
        "id": "lUvy5yJAVmCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group_summary = az.summary(\n",
        "    idata_full,\n",
        "    var_names=[\"1|Country\"],\n",
        "    round_to=2,\n",
        ")\n",
        "print(group_summary)\n"
      ],
      "metadata": {
        "id": "Qs_wwqdKOsUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group_summary1 = az.summary(\n",
        "    idata_full,\n",
        "    var_names=[\"1|Country_sigma\"],\n",
        "    round_to=2,\n",
        ")\n",
        "print(group_summary1)"
      ],
      "metadata": {
        "id": "kaHxfcXZWPZS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
